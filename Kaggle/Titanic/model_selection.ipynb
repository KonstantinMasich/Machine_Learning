{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial prediction\n",
    "So for now we've come to conclusion that PassengerID and Name features can be safely dropped. Now let's get the initial model and prediction now to set a benchmark for our work. We will discard all non-numeric features for now, except for Sex and Embarkation.\n",
    "\n",
    "## Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0       3    0  22.0      1      0   7.2500       2.0\n",
       "1       1    1  38.0      1      0  71.2833       0.0\n",
       "2       3    1  26.0      0      0   7.9250       2.0\n",
       "3       1    1  35.0      1      0  53.1000       2.0\n",
       "4       3    0  35.0      0      0   8.0500       2.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 1. Read data and form X and y\n",
    "train_df = pd.read_csv('train.csv')\n",
    "X = train_df.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], 1)\n",
    "y = train_df['Survived']\n",
    "# 2. Conver male, female and C, Q, S into categorials\n",
    "mapping = {'male': 0, 'female': 1, 'C': 0, 'Q': 1, 'S': 2}\n",
    "X.replace({'Sex': mapping, 'Embarked': mapping}, inplace=True)\n",
    "# 3. Replace NaNs in Age\n",
    "X.fillna(X['Age'].mean(), inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing metrics\n",
    "Titanic competition on Kaggle requires usage of **accuracy** metrics, so this will be the main metrics we use.\n",
    "\n",
    "\n",
    "\n",
    "## Making the initial, fast estimation\n",
    "\n",
    "First of all we will use **KNN** to get some off the bat understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score is: 0.748751217612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "knn = KNeighborsClassifier(n_neighbors=8, weights='distance')\n",
    "scores = cross_val_score(knn, X, y, scoring='accuracy', cv=15)\n",
    "print(\"Mean cross-validated score is:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So right off the bat we got **~0.75** accuracy. This is an expected accuracy for KNN though, because data is not normalized and KNN with 'distance' setting is kind of sensitive to that: if Sex is 0 or 1, Fare can be 7, 8, 71, 53, so in this case KNN would be skewed towards Fare.\n",
    "Let's try the same with LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated scores are: [ 0.77777778  0.78888889  0.7752809   0.80898876  0.79775281  0.76404494\n",
      "  0.79775281  0.7752809   0.84269663  0.81818182]\n",
      "Mean is: 0.794664623766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic regression\n",
    "log_regression = LogisticRegression()\n",
    "scores = cross_val_score(log_regression, X, y, scoring='accuracy', cv=10)\n",
    "print(\"Cross validated scores are:\", scores)\n",
    "print(\"Mean is:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- ROC AUC score ---------\n",
      "Mean CV score is: 0.849027774844\n",
      "--------- Accuracy score ---------\n",
      "Accuracy for some random split: 0.856502242152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Linear regression\n",
    "lin_regression = LinearRegression()\n",
    "\n",
    "# AUC score\n",
    "scores = cross_val_score(lin_regression, X, y, scoring='roc_auc', cv=10)\n",
    "print(\"--------- ROC AUC score ---------\")\n",
    "# print(\"Cross validated scores are:\", scores)\n",
    "print(\"Mean CV score is:\", scores.mean())\n",
    "\n",
    "# Accuracy score via prediction rounding\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "lin_regression.fit(X_train, y_train)\n",
    "y_pred = lin_regression.predict(X_test)\n",
    "print(\"--------- Accuracy score ---------\")\n",
    "print(\"Accuracy for some random split:\", accuracy_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so at this point it seems that KNN is not particulary good here, and LogisticRegression might be the model of choice **for now**.\n",
    "\n",
    "**Here another models will be added and tested as I learn them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Up-to-date Kaggle score\n",
    "As of 23.11.17 the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated score for AdaBoost is: 0.807049426853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.1)\n",
    "result=cross_val_score(ada,X,y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for AdaBoost is:',result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n================================== OUTPUT HERE IS: ==================================\\nFitting 3 folds for each of 120 candidates, totalling 360 fits\\n\\n[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  4.8min finished\\n\\n0.805836139169\\nAdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\\n          learning_rate=0.7, n_estimators=600, random_state=None)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================== OUTPUT HERE IS: ==================================\n",
    "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
    "\n",
    "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  4.8min finished\n",
    "\n",
    "0.805836139169\n",
    "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=0.7, n_estimators=600, random_state=None)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# n_estimators=list(range(100,1100,100))\n",
    "# learn_rate=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "# hyper={'n_estimators':n_estimators,'learning_rate':learn_rate}\n",
    "# gd=GridSearchCV(estimator=AdaBoostClassifier(),param_grid=hyper,verbose=True)\n",
    "# gd.fit(X,y)\n",
    "# print(gd.best_score_)\n",
    "# print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated score for AdaBoost is: 0.812680172512\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=0.7, n_estimators=600, random_state=None)\n",
    "result=cross_val_score(ada,X,y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for AdaBoost is:',result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
